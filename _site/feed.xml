<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-11-05T19:08:19-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Josh Chang PhD</title><subtitle>Josh Chang's academic website and blog.</subtitle><author><name>Josh Chang</name></author><entry><title type="html">Basketball, disability, prediction, and data availability</title><link href="http://localhost:4000/blog/research/basketball/" rel="alternate" type="text/html" title="Basketball, disability, prediction, and data availability" /><published>2019-11-04T00:00:00-05:00</published><updated>2019-11-04T00:00:00-05:00</updated><id>http://localhost:4000/blog/research/basketball</id><content type="html" xml:base="http://localhost:4000/blog/research/basketball/">&lt;p&gt;Tl;dr:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Yes, hot hands exist in basketball&lt;/li&gt;
  &lt;li&gt;People should stop uncritically using Bayes factors&lt;/li&gt;
  &lt;li&gt;Look to sports if you want data to test out ideas&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Oddly enough, for a government-funded mathematical biologist, it looks like I wrote a &lt;a href=&quot;https://royalsocietypublishing.org/doi/full/10.1098/rsos.182174&quot;&gt;manuscript&lt;/a&gt; funded by the Social Security Administration on the hot hand effect in basketball. I thought I should explain a bit how this particular manuscript came to be.&lt;/p&gt;

&lt;h2 id=&quot;ssa-and-disability-adjudication&quot;&gt;SSA and disability adjudication&lt;/h2&gt;

&lt;p&gt;In 2013, I first heard This American Life’s episode &lt;a href=&quot;https://www.thisamericanlife.org/490/trends-with-benefits&quot;&gt;490: Trends With Benefits&lt;/a&gt;, telling stories behind the disability crisis facing the United States. The episode always stuck with me and was a big factor in influencing me to join the NIH Clinical Center’s &lt;a href=&quot;https://clinicalcenter.nih.gov/rmd/eb/ebstaff.html&quot;&gt;Epidemiology and Biostatistics group&lt;/a&gt;, which is sponsored by the US Social Security Administration (SSA) and collaborates with the SSA on disability projects.&lt;/p&gt;

&lt;p&gt;The particular project I was interested in involved using queueing theory to understand the case adjudication backlog. At the time, the backlog was two years. The government was interested in using analytical techniques to improve productivity and target resources in the aim of reducing the backlog.&lt;/p&gt;

&lt;h2 id=&quot;modeling&quot;&gt;Modeling&lt;/h2&gt;

&lt;p&gt;As part of this project, I needed a method of modeling paths which cases take as they traverse through the system at SSA. Enter Markov Chains! However, standard memoryless Markov Chains were not suitable for this problem. There were some stereotyped patterns within case paths though with lots of variability. The simplest extension of memoryless Markov chains are higher-order Markov chains. In these Markov chains, the transition probability depends on the recent history of the trajectory, and not just the current state. I needed a general method for choosing the order.&lt;/p&gt;

&lt;h2 id=&quot;publication&quot;&gt;Publication&lt;/h2&gt;

&lt;p&gt;At the same time, I had been having success using the principle of evaluating Bayesian models based on their frequentist properties. What this entails is evaluating the out-of-sample predictive ability of well-regularized Bayesian model fits. For the Markov chain problem, there are certain metrics that one can compute for performing this evaluation. My original manuscript &lt;a href=&quot;https://arxiv.org/abs/1702.06221&quot;&gt;arXiv:1702.06221&lt;/a&gt; derived formulae for these metrics and evaluated the relative performance of the different metrics using simulated data.
&lt;strong&gt;Notably, Bayes factors are very bad for this problem, if you want to make any mechanistic judgments downstream of your model selection procedure.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Now it came time to publish the results. Editors were not interested in publishing my original manuscript since it didn’t have data or a real-world problem. I didn’t want to use the original social security application, because that information is sensitive. Being from the world of quantitative biology, I immediately started looking for biological applications (transitions between channel states for instance), but came up empty in searching for publicly-available data.&lt;/p&gt;

&lt;h2 id=&quot;hot-hands&quot;&gt;Hot hands&lt;/h2&gt;

&lt;p&gt;Fortunately, at that time, the NBA finals were going on. I realized that &lt;strong&gt;sports data is public.&lt;/strong&gt; Additionally, there had been some debate in the media over the presence of the hot hand effect. As I was watching game two of the 2017 finals, I scrubbed LeBron James’ free throw records from the season prior and lo and behold, I found statistical dependencies in his free throw shooting. He didn’t exhibit hot hands per-se, but he clearly has a tendency to course-correct after missing a free throw. Over several seasons, he has hit a better percentage after a miss than otherwise.&lt;/p&gt;

&lt;p&gt;Going forward in peer review, I eventually extended the analysis to other players, and to entire seasons. If you check out my paper, you will see that based on best-prediction, models for free throws with various types of dependencies between free throws do better than than models without dependencies. This varies by player but there are several general trends: Hot hands, cold hands, error correcting hands. As a variant of cold hands, many players shoot markedly worse on their first trip to the line. I think NBA coaches know this – when a player gets injured and is unable to shoot his free throws, the opposing coach will often choose someone at the end of the injured player’s bench to shoot free throws.&lt;/p&gt;

&lt;p&gt;Additionally, from a mechanistic standpoint, it is no surprise that statistical dependencies between outcomes exist. Anybody who has ever played basketball would tell you that sometimes you are in the zone and sometimes you aren’t feeling it. Shooting a basketball is a sequence of neuronal signals culminating in mechanistic actions. The underlying process is a result of a dynamical system dependent on the state of the player. It makes sense that hot hands exist.&lt;/p&gt;

&lt;p&gt;Anyways, to summarize, no the SSA didn’t fund a sports analytics study. The manuscript looks like a sports analytics study but it is actually a serious scholarly work on evaluating model choices. If there is a tool that you want to use, like AIC, BIC, DIC, or Bayes factors, make sure that you understand how well it works for the particular problem you are working on before you apply it and try to interpret its results.&lt;/p&gt;</content><author><name>Josh Chang</name></author><category term="research" /><category term="statistics" /><category term="bayesian" /><summary type="html">Tl;dr: Yes, hot hands exist in basketball People should stop uncritically using Bayes factors Look to sports if you want data to test out ideas Oddly enough, for a government-funded mathematical biologist, it looks like I wrote a manuscript funded by the Social Security Administration on the hot hand effect in basketball. I thought I should explain a bit how this particular manuscript came to be. SSA and disability adjudication In 2013, I first heard This American Life’s episode 490: Trends With Benefits, telling stories behind the disability crisis facing the United States. The episode always stuck with me and was a big factor in influencing me to join the NIH Clinical Center’s Epidemiology and Biostatistics group, which is sponsored by the US Social Security Administration (SSA) and collaborates with the SSA on disability projects. The particular project I was interested in involved using queueing theory to understand the case adjudication backlog. At the time, the backlog was two years. The government was interested in using analytical techniques to improve productivity and target resources in the aim of reducing the backlog. Modeling As part of this project, I needed a method of modeling paths which cases take as they traverse through the system at SSA. Enter Markov Chains! However, standard memoryless Markov Chains were not suitable for this problem. There were some stereotyped patterns within case paths though with lots of variability. The simplest extension of memoryless Markov chains are higher-order Markov chains. In these Markov chains, the transition probability depends on the recent history of the trajectory, and not just the current state. I needed a general method for choosing the order. Publication At the same time, I had been having success using the principle of evaluating Bayesian models based on their frequentist properties. What this entails is evaluating the out-of-sample predictive ability of well-regularized Bayesian model fits. For the Markov chain problem, there are certain metrics that one can compute for performing this evaluation. My original manuscript arXiv:1702.06221 derived formulae for these metrics and evaluated the relative performance of the different metrics using simulated data. Notably, Bayes factors are very bad for this problem, if you want to make any mechanistic judgments downstream of your model selection procedure. Now it came time to publish the results. Editors were not interested in publishing my original manuscript since it didn’t have data or a real-world problem. I didn’t want to use the original social security application, because that information is sensitive. Being from the world of quantitative biology, I immediately started looking for biological applications (transitions between channel states for instance), but came up empty in searching for publicly-available data. Hot hands Fortunately, at that time, the NBA finals were going on. I realized that sports data is public. Additionally, there had been some debate in the media over the presence of the hot hand effect. As I was watching game two of the 2017 finals, I scrubbed LeBron James’ free throw records from the season prior and lo and behold, I found statistical dependencies in his free throw shooting. He didn’t exhibit hot hands per-se, but he clearly has a tendency to course-correct after missing a free throw. Over several seasons, he has hit a better percentage after a miss than otherwise. Going forward in peer review, I eventually extended the analysis to other players, and to entire seasons. If you check out my paper, you will see that based on best-prediction, models for free throws with various types of dependencies between free throws do better than than models without dependencies. This varies by player but there are several general trends: Hot hands, cold hands, error correcting hands. As a variant of cold hands, many players shoot markedly worse on their first trip to the line. I think NBA coaches know this – when a player gets injured and is unable to shoot his free throws, the opposing coach will often choose someone at the end of the injured player’s bench to shoot free throws. Additionally, from a mechanistic standpoint, it is no surprise that statistical dependencies between outcomes exist. Anybody who has ever played basketball would tell you that sometimes you are in the zone and sometimes you aren’t feeling it. Shooting a basketball is a sequence of neuronal signals culminating in mechanistic actions. The underlying process is a result of a dynamical system dependent on the state of the player. It makes sense that hot hands exist. Anyways, to summarize, no the SSA didn’t fund a sports analytics study. The manuscript looks like a sports analytics study but it is actually a serious scholarly work on evaluating model choices. If there is a tool that you want to use, like AIC, BIC, DIC, or Bayes factors, make sure that you understand how well it works for the particular problem you are working on before you apply it and try to interpret its results.</summary></entry><entry><title type="html">The biggest hurdle we had to overcome in formulating a calcium hypothesis for post-CSD vasoconstriction</title><link href="http://localhost:4000/blog/research/postacute-csd/" rel="alternate" type="text/html" title="The biggest hurdle we had to overcome in formulating a calcium hypothesis for post-CSD vasoconstriction" /><published>2019-10-10T00:00:00-04:00</published><updated>2019-10-10T00:00:00-04:00</updated><id>http://localhost:4000/blog/research/postacute-csd</id><content type="html" xml:base="http://localhost:4000/blog/research/postacute-csd/">About a decade ago now, I entered the field of biology by working in a neuroscience wet lab, studying this phenomenon known as cortical spreading depolarization (depression), or CSD. CSD is a physical wave of ionic movement and activity in cortical brain tissue that occurs in all sorts of pathological states. The lab was studying specifically how vasculature and blood delivery impact the propagation of the wave. A particular phenomenon we focused on, and characterized, was an hour long disturbance in blood supply along with derangements in neurovascular coupling (the matching of blood supply to neuronal activity). Most of the literature on CSD focuses on the minute-long timescale over which the wave is present in terms of intracellular ionic concentrations.

I had always been interested in the mechanism for this hour-long state. In the interim years, I studied the calcium-phosphate regulation machinery in the body, using mathematical modeling. I saw that there was potentially a link between calcium phosphate regulation and the long-term disturbance. My idea was that calcium and phosphate which clustered within mitochondria of smooth muscle cells during CSD can leak out slowly and cause vasoconstriction. The key point here is that the presence of clusters means that the free concentration of calcium  within mitochondria is elevated but not too-highly elevated. Because exchange rates are dependent on free rather than total concentrations, the leakage out of mitochondria is slow.

Perhaps the coolest implication of these mechanisms is potential production of ATP, using aerobic machinery, in the absense of oxygen-dependent substrates. Dissolution of calcium phosphate absorbs protons, increasing the pH within mitochondria. Aerobic ATP production is ultimately driven by H+ gradients across the mitochondrial inner membrane - typically, maintenance of the gradient is performed by pumping protons out of the matrix using chemical potential energy from NADH and FADH2. Removal of protons through this process is another avenue for maintaining the gradient. I looked extensively into the literature and did find anybody characterizing this potential phenomenon.

Over the last couple years a couple collaborators and I have attempted to distill the overall mechanistic picture into a mathematical model in order to study the timescale of the phenomenon and whether it can explain what we see in experiments. We eventually got this paper submitted - it is under review by PLOS Computation Biology currently. I thought it would be useful to comment on some of the difficulties we had when formulating the model.

&lt;!--more--&gt;

In science, we &quot;stand on the shoulders of giants.&quot; What this means in practice is that we are highly dependent on the generalizability of prior results in the literature. I think this is especially true when doing quantitative modeling. The biggest issue here is that when you delve into the literature, you often find that models rely at some point on parameter fits that are highly over-parameterized. Worse, sometimes units within reported models are not consistent (Ahem models containing the NCX - though one of my own prior papers also suffers from this issue).

In our model, we required cellular calcium dynamics, a well-studied subject. However, the bulk of the existing work in the literature suffers from the aforementioned issues, regardless of whether they fit experimental data. Additionally, we required each of the model components to be valid in perturbed states of physiology. For instance, we found that many models of the SERCA pump lead to blow-up in ER calcium concentration within the context of our model, because these models are not mindful of free calcium concentration within the ER, not to mention solubility issues within the ER. We did eventually find a couple suitable SERCA models, though they yielded poor behavior. Delving into the manuscripts where they fit these models, we found that the parameter fits were highly over-parameterized.

Our solution to our issues was to modify some of the parameters to give reasonable behavior (fluxes going in the right direction at about the right magnitude), and to report model outputs over a wide parameter sweep. At a personal level, I find myself somewhat unsatisfied by all of this - the overall project only partially scratched an itch that I had. In order to fully scratch the itch, I would need someone to do detailed mechanism-specific measurements of each of the pumps and channels involved, with careful fitting where uncertainties and parametric dependencies are retained and characterized. Short of this, raw data would have been useful. As a follow-up paper, I hope we can provide better guidance to people when they fit kinetic models to data, so stay tuned...</content><author><name>Josh Chang</name></author><category term="research" /><category term="CSD" /><category term="calcium" /><category term="ODE" /><summary type="html">About a decade ago now, I entered the field of biology by working in a neuroscience wet lab, studying this phenomenon known as cortical spreading depolarization (depression), or CSD. CSD is a physical wave of ionic movement and activity in cortical brain tissue that occurs in all sorts of pathological states. The lab was studying specifically how vasculature and blood delivery impact the propagation of the wave. A particular phenomenon we focused on, and characterized, was an hour long disturbance in blood supply along with derangements in neurovascular coupling (the matching of blood supply to neuronal activity). Most of the literature on CSD focuses on the minute-long timescale over which the wave is present in terms of intracellular ionic concentrations. I had always been interested in the mechanism for this hour-long state. In the interim years, I studied the calcium-phosphate regulation machinery in the body, using mathematical modeling. I saw that there was potentially a link between calcium phosphate regulation and the long-term disturbance. My idea was that calcium and phosphate which clustered within mitochondria of smooth muscle cells during CSD can leak out slowly and cause vasoconstriction. The key point here is that the presence of clusters means that the free concentration of calcium within mitochondria is elevated but not too-highly elevated. Because exchange rates are dependent on free rather than total concentrations, the leakage out of mitochondria is slow. Perhaps the coolest implication of these mechanisms is potential production of ATP, using aerobic machinery, in the absense of oxygen-dependent substrates. Dissolution of calcium phosphate absorbs protons, increasing the pH within mitochondria. Aerobic ATP production is ultimately driven by H+ gradients across the mitochondrial inner membrane - typically, maintenance of the gradient is performed by pumping protons out of the matrix using chemical potential energy from NADH and FADH2. Removal of protons through this process is another avenue for maintaining the gradient. I looked extensively into the literature and did find anybody characterizing this potential phenomenon. Over the last couple years a couple collaborators and I have attempted to distill the overall mechanistic picture into a mathematical model in order to study the timescale of the phenomenon and whether it can explain what we see in experiments. We eventually got this paper submitted - it is under review by PLOS Computation Biology currently. I thought it would be useful to comment on some of the difficulties we had when formulating the model.</summary></entry></feed>